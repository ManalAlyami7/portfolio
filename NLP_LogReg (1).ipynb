{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting Google Drive to Access Files"
      ],
      "metadata": {
        "id": "dn6iLMyMLtJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwhdgfpajGAF",
        "outputId": "1ac1dd3d-4edf-4ee3-ccc3-1c5a7e4d291c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data from Google Drive into a Pandas DataFrame\""
      ],
      "metadata": {
        "id": "PxfSJB3jL2QZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to your file in Google Drive\n",
        "file_path = '/content/drive/MyDrive/combinedData.csv'\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(file_path)\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut_W8XlRjISr",
        "outputId": "d8c7c211-2ff4-4e2e-af42-3fa2e2da9fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  id                                          statement   status\n",
            "0  0                                         oh my gosh  Anxiety\n",
            "1  1  trouble sleeping, confused mind, restless hear...  Anxiety\n",
            "2  2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n",
            "3  3  I've shifted my focus to something else but I'...  Anxiety\n",
            "4  4  I'm restless and restless, it's been a month n...  Anxiety\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing for Text Preprocessing and Model Training"
      ],
      "metadata": {
        "id": "bZbOp2iEL_P0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "# Ensure necessary NLTK resources are available\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "# Initialize the Lemmatizer and Stemmer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICzofeR2y1eH",
        "outputId": "5ef47f12-853d-4321-8fbe-8e64f510916a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing: Tokenization, Lemmatization, and Stemming without stopwords removal"
      ],
      "metadata": {
        "id": "qq5-H59NMHkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def preprocess_text(text):\n",
        "    # Lowercase the text\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove special characters, numbers, and punctuation, but keep text-based ones\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Apply stemming\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    # Apply lemmatization\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    # Rejoin the tokens into a single string\n",
        "    return \" \".join(tokens)"
      ],
      "metadata": {
        "id": "zBe4lVDXFUnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Data: Handling Missing Values and Preprocessing Text"
      ],
      "metadata": {
        "id": "lgSfDsD_MZps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the dataset is in a DataFrame 'data' with 'statement' and 'status'\n",
        "X = data['statement']  # Column with the text data\n",
        "y = data['status']  # Column with sentiment labels (7 classes)\n",
        "\n",
        "# Remove rows with missing text (if any)\n",
        "data = pd.concat([X, y], axis=1).dropna()  # Drop rows where either X or y has NaN values\n",
        "\n",
        "# Re-assign X and y after dropna\n",
        "X = data['statement']\n",
        "y = data['status']\n",
        "X = X.apply(preprocess_text)\n",
        "\n",
        "# Check if the lengths are consistent\n",
        "print(f\"Length of X: {len(X)}, Length of y: {len(y)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idSRSGITFZ-3",
        "outputId": "ab63aa22-88f7-4567-d381-8aef6ce24add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of X: 52680, Length of y: 52680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label Encoding and TF-IDF Vectorization for Text Classification"
      ],
      "metadata": {
        "id": "Axwl4KfHMqGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels (e.g., 'Anxiety' -> 0, 'Depression' -> 1, etc.)\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "# Convert text to TF-IDF features\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "X_tfidf = vectorizer.fit_transform(X)"
      ],
      "metadata": {
        "id": "CXhxqu_HFdca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting Data into Training and Testing Sets"
      ],
      "metadata": {
        "id": "45QYO51vMyIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y_encoded, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "62RkEZgfFhpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning with GridSearchCV for Logistic Regression"
      ],
      "metadata": {
        "id": "eFfndET8NHbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "# Manually specify the best hyperparameters from GridSearch results\n",
        "best_params = {\n",
        "    'C': 10,\n",
        "    'max_iter': 1000,\n",
        "    'solver': 'saga'\n",
        "}\n",
        "\n",
        "# Initialize the logistic regression model with the best hyperparameters\n",
        "best_logreg_model = OneVsRestClassifier(LogisticRegression(n_jobs=-1, C=best_params['C'], max_iter=best_params['max_iter'], solver=best_params['solver']))\n",
        "start_time = time.time()\n"
      ],
      "metadata": {
        "id": "QcEYr6cyFitA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation and Performance Metrics"
      ],
      "metadata": {
        "id": "Gq2d9eLrNTHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model using the training data\n",
        "best_logreg_model.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "# Evaluate performance on test set\n",
        "y_pred = best_logreg_model.predict(X_test)\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=encoder.classes_))\n",
        "\n",
        "training_time = end_time - start_time\n",
        "print(f\"Training Time: {training_time / 60:.2f} Minutes\")\n"
      ],
      "metadata": {
        "id": "nceqFx-AFlyk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f4a3be6-7129-43e2-afef-1d134e78ef15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "             Anxiety       0.80      0.78      0.79       754\n",
            "             Bipolar       0.85      0.75      0.79       554\n",
            "          Depression       0.71      0.72      0.72      3058\n",
            "              Normal       0.87      0.96      0.91      3325\n",
            "Personality disorder       0.83      0.61      0.70       220\n",
            "              Stress       0.67      0.50      0.57       530\n",
            "            Suicidal       0.68      0.65      0.67      2095\n",
            "\n",
            "            accuracy                           0.78     10536\n",
            "           macro avg       0.77      0.71      0.74     10536\n",
            "        weighted avg       0.77      0.78      0.77     10536\n",
            "\n",
            "Training Time: 2.94 Minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6frKTSjiurh",
        "outputId": "8ac3b883-e7f6-4ef5-93d6-71d43a4f8c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.78\n",
            "Precision: 0.77\n",
            "Recall: 0.78\n",
            "F1 Score: 0.77\n",
            "Confusion Matrix:\n",
            "[[ 590   14   60   52    8   25    5]\n",
            " [  22  415   69   22    4   16    6]\n",
            " [  53   39 2213  135    9   40  569]\n",
            " [  13    5   64 3183    0   27   33]\n",
            " [   5    6   33   25  134   14    3]\n",
            " [  53   10   80   98    7  265   17]\n",
            " [   1    2  589  128    0    8 1367]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Optional: Model Testing and Sentiment Prediction on New Data with Confidence"
      ],
      "metadata": {
        "id": "FnmsqacWP1Cr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example list of sentences\n",
        "sentences = [\n",
        "    'I feel really overwhelmed and anxious these days.',\n",
        "    'I am so happy and excited about the upcoming event!',\n",
        "    'I can’t stop feeling sad and depressed lately.',\n",
        "    'Everything seems fine, I feel completely normal.',\n",
        "    'I am struggling with so much stress these days.',\n",
        "    'My mind is constantly racing, I feel suicidal.',\n",
        "    'I’ve been feeling confused and not myself lately.'\n",
        "]\n",
        "\n",
        "# Preprocess the sentences\n",
        "processed_sentences = [preprocess_text(sentence) for sentence in sentences]\n",
        "\n",
        "# Convert the preprocessed text to TF-IDF features\n",
        "X_new_tfidf = vectorizer.transform(processed_sentences)\n",
        "\n",
        "# Get the prediction probabilities (confidence scores) for each sentence\n",
        "probabilities = best_logreg_model.predict_proba(X_new_tfidf)\n",
        "\n",
        "# Make predictions\n",
        "predictions = best_logreg_model.predict(X_new_tfidf)\n",
        "\n",
        "# Decode the predictions back to the original labels\n",
        "predicted_labels = encoder.inverse_transform(predictions)\n",
        "\n",
        "# Enhanced output with confidence and ethical warnings\n",
        "for sentence, label, prob in zip(sentences, predicted_labels, probabilities):\n",
        "    # Get the maximum confidence score (probability) for the predicted class\n",
        "    confidence = prob.max()\n",
        "\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Predicted Sentiment: {label} (Confidence: {confidence*100:.2f}%)\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "O7BJvAEkyFbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd0c9a6-f854-4505-d177-35de100c9c23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: I feel really overwhelmed and anxious these days.\n",
            "Predicted Sentiment: Anxiety (Confidence: 60.79%)\n",
            "\n",
            "\n",
            "Sentence: I am so happy and excited about the upcoming event!\n",
            "Predicted Sentiment: Normal (Confidence: 88.19%)\n",
            "\n",
            "\n",
            "Sentence: I can’t stop feeling sad and depressed lately.\n",
            "Predicted Sentiment: Depression (Confidence: 88.42%)\n",
            "\n",
            "\n",
            "Sentence: Everything seems fine, I feel completely normal.\n",
            "Predicted Sentiment: Depression (Confidence: 77.73%)\n",
            "\n",
            "\n",
            "Sentence: I am struggling with so much stress these days.\n",
            "Predicted Sentiment: Stress (Confidence: 65.49%)\n",
            "\n",
            "\n",
            "Sentence: My mind is constantly racing, I feel suicidal.\n",
            "Predicted Sentiment: Suicidal (Confidence: 78.03%)\n",
            "\n",
            "\n",
            "Sentence: I’ve been feeling confused and not myself lately.\n",
            "Predicted Sentiment: Normal (Confidence: 89.23%)\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}